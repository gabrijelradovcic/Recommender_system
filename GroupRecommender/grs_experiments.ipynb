{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for evaluating the explanations of the Group Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ask the user the same questionnaire as the individual experiment. But do not recommend. \n",
    "2. Instead add the user to the user matrix for group recommender system.\n",
    "3. Now start the group recommender setup as usual; fill in the NaN with knn collaboartive filtering, make 4 clusters, and make groups. \n",
    "4. Display the explanations for the group in which the user we created initially is in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from lenskit import batch, topn\n",
    "from nltk.corpus import stopwords\n",
    "from tkinter import messagebox\n",
    "from lenskit import crossfold as xf\n",
    "from nltk.tokenize import word_tokenize\n",
    "from lenskit.metrics import topn as tnmetrics\n",
    "from lenskit.algorithms import Recommender\n",
    "from lenskit.algorithms.user_knn import UserUser\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lenskit import topn\n",
    "from lenskit import crossfold as xf\n",
    "from lenskit import batch, topn, util\n",
    "from lenskit.algorithms import Recommender, user_knn as uknn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(action='ignore', category=RuntimeWarning, module='lenskit.metrics.topn')\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning, module='lenskit.metrics.topn')\n",
    "from surprise.model_selection import cross_validate\n",
    "from lenskit.algorithms import Recommender, bias, basic, item_knn\n",
    "from lenskit.algorithms.user_knn import UserUser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset_folder = \"../Data/PreprocessedDataset\"\n",
    "ratings_df = pd.read_csv(preprocessed_dataset_folder+\"/ratings.csv\")\n",
    "movies_df = pd.read_csv(preprocessed_dataset_folder+\"/movies.csv\")\n",
    "user_plots_ratings_df = pd.read_csv(preprocessed_dataset_folder+\"/user_plots.csv\") #first run notebook algorithm_experiments to get this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_misery_strategy(group, n_movies):\n",
    "\n",
    "    if 'cluster' in group.columns:\n",
    "        group = group.drop(columns=['cluster'])\n",
    "\n",
    "    min_ratings = group.min(axis=0)\n",
    "    sorted_movies = min_ratings.sort_values(ascending=False)\n",
    "    return sorted_movies.head(n_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_pleasure_strategy(group, n_movies):\n",
    "\n",
    "    if 'cluster' in group.columns:\n",
    "        group = group.drop(columns=['cluster'])\n",
    "\n",
    "    max_ratings = group.max(axis=0)\n",
    "    sorted_movies = max_ratings.sort_values(ascending=False)\n",
    "    return sorted_movies.head(n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_strategy(group, n_movies, threshold=4): \n",
    "    print(group)\n",
    "    likes = group[group >= threshold]\n",
    "    like_counts = likes.count()\n",
    "    majority_threshold = len(group) / 2\n",
    "    majority_likes = like_counts[like_counts > majority_threshold]\n",
    "    return majority_likes.nlargest(n_movies)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approval_voting_strategy(group, n_movies):         \n",
    "    if 'cluster' in group.columns:\n",
    "        group = group.drop(columns=['cluster'])\n",
    "\n",
    "    approval_threshold = 4 \n",
    "    approved_items_count = (group > approval_threshold).sum(axis=0)\n",
    "    sorted_movies = approved_items_count.sort_values(ascending=False)\n",
    "    \n",
    "    return (sorted_movies.head(n_movies))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additive_utilitarian_strategy(group, n_movies):\n",
    "\n",
    "    if 'cluster' in group.columns:\n",
    "        group = group.drop(columns=['cluster'])\n",
    "\n",
    "    total_ratings = group.sum(axis=0)\n",
    "    sorted_movies = total_ratings.sort_values(ascending=False)\n",
    "    return (sorted_movies.head(n_movies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minority_groups(clusters, num_of_groups, group_size=4):\n",
    "    all_groups = {}\n",
    "    group_count = 0\n",
    "\n",
    "    viable_clusters = [group for _, group in clusters if len(group) >= 1]\n",
    "\n",
    "    while group_count < num_of_groups:\n",
    "        for cluster_combination in itertools.permutations(viable_clusters, 2):\n",
    "            cluster_a, cluster_b = cluster_combination\n",
    "            if len(cluster_a) >= group_size - 1 and len(cluster_b) >= 1:\n",
    "                sampled_users_a = cluster_a.sample(n=group_size - 1)\n",
    "                sampled_user_b = cluster_b.sample(n=1)\n",
    "                group_of_sampled_users = pd.concat([sampled_users_a, sampled_user_b])\n",
    "                all_groups[f'group_{group_count+1}'] = group_of_sampled_users\n",
    "                group_count += 1\n",
    "\n",
    "                if group_count >= num_of_groups:\n",
    "                    break\n",
    "\n",
    "    return all_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coalitional_groups(clusters, user_id):\n",
    "    user_cluster_id = None\n",
    "    for cluster_id, group in clusters:\n",
    "        if user_id in group.index:\n",
    "            user_cluster_id = cluster_id\n",
    "            break\n",
    "\n",
    "\n",
    "    user_cluster_df = [group for cluster_id, group in clusters if cluster_id == user_cluster_id][0]\n",
    "    sampled_user_from_same_cluster = user_cluster_df.drop(user_id).sample(n=1)\n",
    "    other_clusters = [group for cluster_id, group in clusters if cluster_id != user_cluster_id]\n",
    "    chosen_cluster = random.choice(other_clusters)  # Randomly choose another cluster\n",
    "    sampled_users_from_other_cluster = chosen_cluster.sample(n=2)\n",
    "    group = pd.concat([user_cluster_df.loc[[user_id]], sampled_user_from_same_cluster, sampled_users_from_other_cluster])\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def minority_groups(clusters, user_id):\n",
    "    user_cluster_id = None\n",
    "    for cluster_id, group in clusters:\n",
    "        if user_id in group.index:\n",
    "            user_cluster_id = cluster_id\n",
    "            break\n",
    "\n",
    "    other_clusters = [group for cluster_id, group in clusters if cluster_id != user_cluster_id]\n",
    "    chosen_cluster = random.choice(other_clusters)\n",
    "    sampled_users = chosen_cluster.sample(n=3)\n",
    "    user_cluster_df = [group for cluster_id, group in clusters if cluster_id == user_cluster_id][0]\n",
    "    group = pd.concat([user_cluster_df.loc[[user_id]], sampled_users])\n",
    "\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_group(clusters, user_id):\n",
    "    user_cluster = None\n",
    "    for cluster_id, group in clusters:\n",
    "        if user_id in group.index:\n",
    "            user_cluster = group\n",
    "            break\n",
    "    if user_cluster is None:\n",
    "        raise ValueError(f\"User ID {user_id} not found in any cluster.\")\n",
    "    sampled_users = user_cluster.drop(user_id).sample(n=3)\n",
    "    uniform_group = pd.concat([user_cluster.loc[[user_id]], sampled_users])\n",
    "\n",
    "    return uniform_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divergent_groups(clusters, num_of_groups, user_id):\n",
    "    all_groups = {}\n",
    "\n",
    "    user_cluster_id = None\n",
    "    for cluster_id, group in clusters:\n",
    "        if user_id in group.index:  \n",
    "            user_cluster_id = cluster_id\n",
    "            break\n",
    "    for i in range(num_of_groups):\n",
    "        sampled_users = []\n",
    "        for cluster_id, group in clusters:\n",
    "            if not group.empty:\n",
    "                if cluster_id == user_cluster_id:\n",
    "                    sampled_users.append(group.loc[[user_id]])\n",
    "                else:\n",
    "                    sampled_user = group.sample(n=1)\n",
    "                    sampled_users.append(sampled_user)\n",
    "\n",
    "        group_of_sampled_users = pd.concat(sampled_users)\n",
    "        all_groups[f'group_{i+1}'] = group_of_sampled_users\n",
    "\n",
    "    return all_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_title(movie_id):\n",
    "    movie_row = movies_df[movies_df['item'] == movie_id]\n",
    "    return movie_row.iloc[0]['title']\n",
    "\n",
    "\n",
    "def generate_explanations(group, aggregation_strat, n_of_recommendations):\n",
    "    explanations = list()\n",
    "\n",
    "    if(aggregation_strat == \"ADD\"):\n",
    "        group_results = additive_utilitarian_strategy(group ,n_of_recommendations)\n",
    "        recommended_movies = ', '.join(map(lambda id_: f\"'{get_movie_title(id_)}'\", group_results.index))\n",
    "        if(len(group_results)>1):\n",
    "            explanations.append(f\"No explanation: We advise your group to consider movies {recommended_movies}.\")\n",
    "            explanations.append(f\"Basic explanation: Movies {recommended_movies} have been recommended to your group because they hold the maximum cumulative rating.\")\n",
    "            explanations.append(f\"Detailed explanation: Movies {recommended_movies} have been recommended to your group because they hold the maximum cumulative rating. This means after adding all group members ratings’ for all movies, movies {recommended_movies} have the highest sum.\")\n",
    "        else:\n",
    "            explanations.append(f\"No explanation: We advise your group to consider movie {recommended_movies}.\")\n",
    "            explanations.append(f\"Basic explanation: Movie {recommended_movies} has been recommended to your group because it holds the maximum cumulative rating.\")\n",
    "            explanations.append(f\"Detailed explanation: Movie {recommended_movies} has been recommended to your group because it holds the maximum cumulative rating. This means after adding all group members ratings’ for all movies, movie {recommended_movies} had the highest sum.\")\n",
    "    if(aggregation_strat == \"APP\"):\n",
    "        group_results = approval_voting_strategy(group, n_of_recommendations)\n",
    "        recommended_movies = ', '.join(map(lambda id_: f\"'{get_movie_title(id_)}'\", group_results.index))\n",
    "        if(len(group_results)>1):\n",
    "            explanations.append(f\"No explanation: We advise your group to consider movies {recommended_movies}.\")\n",
    "            explanations.append(f\"Basic explanation: Movies {recommended_movies} have been recommended to your group because they have the highest amount of ratings above threshold θ.\")\n",
    "            explanations.append(f\"Detailed explanation: Movies {recommended_movies} have been recommended to your group because they have the highest amount of ratings above threshold θ . This means after gathering all group members ratings for each movie, movies {recommended_movies} have the most ratings above θ.\")\n",
    "        else:\n",
    "            explanations.append(f\"No explanation: We advise your group to consider movie {recommended_movies}.\")\n",
    "            explanations.append(f\"Basic explanation: Movie {recommended_movies} has been recommended to your group because it has the highest amount of ratings above threshold θ.\")\n",
    "            explanations.append(f\"Detailed explanation: Movie {recommended_movies} has been recommended to your group because it has the highest amount of ratings above threshold θ . This means after gathering all group members ratings for each movie, movie {recommended_movies} had the most ratings above θ.\")\n",
    "    if(aggregation_strat == \"LMS\"):\n",
    "        group_results = least_misery_strategy(group, n_of_recommendations)\n",
    "        recommended_movies = ', '.join(map(lambda id_: f\"'{get_movie_title(id_)}'\", group_results.index))\n",
    "        if(len(group_results)>1):\n",
    "            explanations.append(f\"No explanation: We advise your group to consider movies {recommended_movies}.\")\n",
    "            explanations.append(f\"Basic explanation: Movies {recommended_movies} have been recommended to your group as they don't pose significant issues for any member.\")\n",
    "            explanations.append(f\"Detailed explanation: Movies {recommended_movies} have been recommended to your group as they don't pose significant issues for any member. This means that for all movies rated, the highest ratings amongst all lowest ratings per movie was the lowest rating of movies {recommended_movies}.\")\n",
    "        else:\n",
    "            explanations.append(f\"No explanation: We advise your group to consider movie {recommended_movies}.\")\n",
    "            explanations.append(f\"Basic explanation: Movie {recommended_movies} has been recommended to your group as it doesn't pose significant issues for any member.\")\n",
    "            explanations.append(f\"Detailed explanation: Movie {recommended_movies} has been recommended to group your group as it doesn't pose significant issues for any member. This means that for all movies rated, the highest rating amongst all lowest ratings per movie was the lowest rating of movie {recommended_movies}.\")\n",
    "    if(aggregation_strat == \"MPL\"):\n",
    "        group_results = most_pleasure_strategy(group, n_of_recommendations)\n",
    "        recommended_movies = ', '.join(map(lambda id_: f\"'{get_movie_title(id_)}'\", group_results.index))\n",
    "        if(len(group_results)>1):\n",
    "            explanations.append(f\"No explanation: We advise your group to consider movies {recommended_movies}.\")\n",
    "            explanations.append(f\"Basic explanation: Movies {recommended_movies} are recommended to your group as they have received the highest ratings from all members.\")\n",
    "            explanations.append(f\"Detailed explanation: Movies {recommended_movies} are recommended to your group as they have received the highest ratings from all members. This means that for the highest ratings from all group members for each movie, movies {recommended_movies} had the highest rating.\")\n",
    "        else:\n",
    "            explanations.append(f\"No explanation: We advise your group to consider movie {recommended_movies}.\")\n",
    "            explanations.append(f\"Basic explanation: Movie {recommended_movies} is recommended to your group as it has received the highest ratings from all members.\")\n",
    "            explanations.append(f\"Detailed explanation: Movie {recommended_movies} is recommended to your group as it has received the highest ratings from all members. This means that for the highest ratings from all group members for each movie, movie {recommended_movies} had the highest rating.\")\n",
    "    if(aggregation_strat == \"MAJ\"):\n",
    "        group_results = majority_strategy(group, n_of_recommendations)\n",
    "        recommended_movies = ', '.join(map(lambda id_: f\"'{get_movie_title(id_)}'\", group_results.index))\n",
    "        if(len(group_results)>1):\n",
    "            explanations.append(f\"No explanation: We advise your group to consider movies {recommended_movies}.\")\n",
    "            explanations.append(f\"Basic explanation: Movies {recommended_movies} are suggested to your group as they are favored by the majority of members.\")\n",
    "            explanations.append(f\"Detailed explanation: Movies {recommended_movies} are suggested to your group as  they are favored by the majority of members. This means the majority of the members in the group gave them a high rating.\")\n",
    "        else:\n",
    "            explanations.append(f\"No explanation: We advise your group to consider movie {recommended_movies}.\")\n",
    "            explanations.append(f\"Basic explanation: Movie {recommended_movies} is suggested to your group as it is favored by the majority of members.\")\n",
    "            explanations.append(f\"Detailed explanation: Movie {recommended_movies} is suggested to your group as it is favored by the majority of members. This means the majority of the members in the group gave it a high rating.\")\n",
    "\n",
    "    return explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExplanations(recommended_movies, cosine_sim_df,user_plots_ratings_df, user_id,k=3):\n",
    "    explanations = []\n",
    "    for index, row in recommended_movies.iterrows():\n",
    "        recommended_item_id = row['item']\n",
    "        item_title = row['title']\n",
    "        string = f\"Recommended item \\\" {item_title}\\\" because you previously watched items with similar plot:\"\n",
    "        explanations.append(string)\n",
    "        print(string)\n",
    "        cosine_sim_values = cosine_sim_df.loc[recommended_item_id].sort_values(ascending=False)\n",
    "        \n",
    "        similar_items = cosine_sim_values.index[0:k]\n",
    "        \n",
    "        similar_items_info = []\n",
    "        for similar_item_id in similar_items:\n",
    "            similar_item_title = movies_df[movies_df['item'] == similar_item_id]['title'].values[0]\n",
    "            similar_item_rating = user_plots_ratings_df[(user_plots_ratings_df['item'] == similar_item_id) & (user_plots_ratings_df['user_id'] == user_id)]['rating'].values[0]\n",
    "            similar_items_info.append((similar_item_id, similar_item_title, similar_item_rating))\n",
    "        \n",
    "        for i, (similar_item_id, similar_item_title, similar_item_rating) in enumerate(similar_items_info):\n",
    "            string2 = f\" {i+1})  \\\"{similar_item_title}\\\" (ID: {similar_item_id}) and gave rating: {similar_item_rating}\"\n",
    "            explanations.append(string2)\n",
    "            print(string2)\n",
    "    return explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    preprocessed_dataset_folder = \"../Data/PreprocessedDataset\"\n",
    "    ratings_df = pd.read_csv(preprocessed_dataset_folder+\"/ratings.csv\")\n",
    "    movies_df = pd.read_csv(preprocessed_dataset_folder+\"/movies.csv\")\n",
    "    user_plots_ratings_df = pd.read_csv(preprocessed_dataset_folder+\"/user_plots.csv\") #first run notebook algorithm_experiments to get this data\n",
    "    return ratings_df, movies_df, user_plots_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(n_of_clusters,user_matrix_filled,n_runs=100):\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(user_matrix_filled)\n",
    "\n",
    "    best_centers = None\n",
    "    best_labels = None\n",
    "    min_inertia = float('inf')\n",
    "\n",
    "    for i in range(n_runs):\n",
    "        kmeans = KMeans(n_clusters=n_of_clusters, random_state=i).fit(scaled_data)\n",
    "        if kmeans.inertia_ < min_inertia:\n",
    "            min_inertia = kmeans.inertia_\n",
    "            best_centers = kmeans.cluster_centers_\n",
    "            best_labels = kmeans.labels_\n",
    "\n",
    "    user_matrix_filled['cluster'] = best_labels\n",
    "    grouped = user_matrix_filled.groupby('cluster')\n",
    "\n",
    "    return best_centers, grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_filtering(data):\n",
    "    algo = UserUser(15,min_nbrs=3) \n",
    "    algo = Recommender.adapt(algo)\n",
    "    algo.fit(data)\n",
    "\n",
    "    user_ids = data['user'].unique()  \n",
    "    item_ids = data['item'].unique() \n",
    "\n",
    "    all_preds = []\n",
    "\n",
    "    for user in user_ids:\n",
    "        preds = algo.predict_for_user(user, item_ids)\n",
    "        for item, pred in zip(item_ids, preds):\n",
    "            if not np.isnan(pred): \n",
    "                all_preds.append([user, item, pred])\n",
    "\n",
    "    pred_df = pd.DataFrame(all_preds, columns=['user', 'item', 'rating'])\n",
    "    filled_user_matrix = pred_df.pivot(index='user', columns='item', values='rating')\n",
    "    filled_user_matrix.fillna(0, inplace=True)\n",
    "    return filled_user_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_plot_text(plot_text):\n",
    "    tokens = word_tokenize(plot_text.replace(\"|\",\" \")) # to split genres\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word.lower() for word in tokens if word.isalnum() and word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "movies_df['plot + title + genres'] = (movies_df['plot']+\" \"+movies_df['title']+\" \"+movies_df['genres']).apply(preprocess_plot_text)\n",
    "def get_user_rated_movies_plots(new_user_df, movies):\n",
    "    rated_item_ids = list(movies)\n",
    "    rated_movies_df = movies_df[movies_df['item'].isin(rated_item_ids)]\n",
    "    rated_movies_df = pd.merge(rated_movies_df[['item', 'plot + title + genres']], new_user_df, on='item')\n",
    "    rated_movies_df['user_id'] = 0\n",
    "    return rated_movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieRatingGUI:\n",
    "    def __init__(self, root, movies):\n",
    "        self.root = root\n",
    "        self.movies = movies\n",
    "        self.ratings = {}\n",
    "        self.create_movie_rating_form(submit_button_size=(20, 5), submit_button_position=(600, 300))\n",
    "\n",
    "    def create_movie_rating_form(self, submit_button_size, submit_button_position):\n",
    "        enlarged_width = 800  \n",
    "        enlarged_height = 600\n",
    "\n",
    "        self.root.geometry(f\"{enlarged_width}x{enlarged_height}\")\n",
    "        title_label = tk.Label(self.root, text=\"Pick at least 15 movies which you watched:\", font=(\"Arial\", 20))\n",
    "        title_label.pack()\n",
    "        scrollbar = tk.Scrollbar(self.root, orient=tk.VERTICAL)\n",
    "        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        self.movie_listbox = tk.Listbox(self.root, yscrollcommand=scrollbar.set, selectmode=tk.MULTIPLE, font=(\"Arial\", 15), height=20, width=50)\n",
    "        for movie in self.movies:\n",
    "            self.movie_listbox.insert(tk.END, movie)\n",
    "        self.movie_listbox.pack(side=tk.LEFT, padx=20, pady=20)\n",
    "        scrollbar.config(command=self.movie_listbox.yview)\n",
    "\n",
    "       \n",
    "        submit_button = tk.Button(self.root, text=\"Submit\", command=self.submit_ratings, width=submit_button_size[0], height=submit_button_size[1], bg=\"red\")\n",
    "        submit_button.place(x=submit_button_position[0], y=submit_button_position[1])\n",
    "       \n",
    "\n",
    "    def submit_ratings(self):\n",
    "        selected_movies_indices = self.movie_listbox.curselection()\n",
    "        if len(selected_movies_indices) < 15:\n",
    "            messagebox.showerror(\"Error\", \"Please select at least 15 movies.\")\n",
    "        else:\n",
    "            selected_movies = [self.movies[index] for index in selected_movies_indices]\n",
    "            if len(selected_movies) > 15:\n",
    "                selected_movies = selected_movies[:15]  \n",
    "            self.show_selected_movies(selected_movies)\n",
    "\n",
    "    def show_selected_movies(self, movies):\n",
    "        data, movies_df, user_plots_ratings_df = load_dataset()\n",
    "        new_window = tk.Tk()\n",
    "        new_window.title(\"Rate Selected Movies\")\n",
    "        movie_ratings = {}\n",
    "\n",
    "        for movie in movies:\n",
    "            label = tk.Label(new_window, text=movie, font=(\"Arial\", 10))\n",
    "            label.grid(row=movies.index(movie), column=0, sticky=\"w\", padx=10, pady=1)\n",
    "            rating_scale = tk.Scale(new_window, from_=0, to=5, orient=tk.HORIZONTAL, resolution=0.1)\n",
    "            rating_scale.grid(row=movies.index(movie), column=1, padx=10, pady=1)\n",
    "            movie_ratings[movie] = rating_scale\n",
    "\n",
    "        users_df = pd.read_csv(preprocessed_dataset_folder+\"/users_for_groups.csv\")\n",
    "        users_available = users_df['user'].nunique()\n",
    "        print(users_available)\n",
    "\n",
    "        if users_available > 3:\n",
    "            submit_button = tk.Button(new_window, text=\"Submit Ratings - Recommendation possible\", command=lambda: self.submit_ratings_with_ratings(new_window, movie_ratings))\n",
    "            submit_button.grid(row=len(movies), columnspan=2, pady=10)\n",
    "        else:            \n",
    "            submit_button = tk.Button(new_window, text=\"Submit Ratings - Recommendation not possible\", command=lambda: self.submit_to_csv(movie_ratings, data))\n",
    "            submit_button.grid(row=len(movies), columnspan=2, pady=10)\n",
    "                    \n",
    "    \n",
    "    def submit_to_csv(self, movie_ratings, data):\n",
    "        existing_data = pd.read_csv(preprocessed_dataset_folder+\"/users_for_groups.csv\")\n",
    "        new_user = [{'title': movie, 'rating': float(rating.get())} for movie, rating in movie_ratings.items()]\n",
    "        new_user_df = pd.DataFrame(new_user)\n",
    "        selected_titles = new_user_df['title'].tolist()\n",
    "        filtered_movies_df = movies_df[movies_df['title'].isin(selected_titles)]\n",
    "        \n",
    "        new_user_df = pd.merge(new_user_df, filtered_movies_df[['item', 'title']], on='title')\n",
    "        user_plot = get_user_rated_movies_plots(new_user_df, filtered_movies_df['item'])\n",
    "        user_plot_all = pd.concat([user_plots_ratings_df, user_plot], axis=0)\n",
    "        if 'user' in existing_data.columns and not existing_data['user'].empty:\n",
    "            new_user_id = existing_data['user'].max() + 1\n",
    "        else:\n",
    "            new_user_id = 1        \n",
    "        rows_to_add = []\n",
    "        for index, entry in user_plot_all.iterrows():\n",
    "            movie_id = movies_df[movies_df['title'] == entry[\"title\"]]['item'].values\n",
    "            if len(movie_id) > 0: \n",
    "                rows_to_add.append({\n",
    "                    'user': new_user_id,\n",
    "                    'item': movie_id[0],\n",
    "                    'rating': entry['rating'],\n",
    "                    'timestamp': 0 \n",
    "                })\n",
    "\n",
    "        new_user_data = pd.DataFrame(rows_to_add)\n",
    "        updated_data = existing_data.append(new_user_data, ignore_index=True)\n",
    "        updated_data.to_csv(preprocessed_dataset_folder+\"/users_for_groups.csv\", index=False)\n",
    "            \n",
    " \n",
    "    def submit_ratings_with_ratings(self, window, movie_ratings):\n",
    "        data1, movies_df, user_plots_ratings_df = load_dataset()\n",
    "        new_user = [{'title': movie, 'rating': float(rating.get())} for movie, rating in movie_ratings.items()]\n",
    "        data = pd.read_csv(preprocessed_dataset_folder+\"/users_for_groups.csv\")\n",
    "        new_user_df = pd.DataFrame(new_user)\n",
    "                \n",
    "        selected_titles = new_user_df['title'].tolist()\n",
    "        filtered_movies_df = movies_df[movies_df['title'].isin(selected_titles)]\n",
    "        new_user_df = pd.merge(new_user_df, filtered_movies_df[['item', 'title']], on='title')\n",
    "        user_plot = get_user_rated_movies_plots(new_user_df, filtered_movies_df['item'])\n",
    "        user_plot_all = pd.concat([user_plots_ratings_df, user_plot], axis=0)\n",
    "        new_user_id = data['user'].max() + 1\n",
    "        rows_to_add = []\n",
    "        for index, entry in user_plot_all.iterrows():\n",
    "            movie_id = movies_df[movies_df['title'] == entry[\"title\"]]['item'].values\n",
    "\n",
    "            if len(movie_id) > 0: \n",
    "                rows_to_add.append({\n",
    "                    'user': new_user_id,\n",
    "                    'item': movie_id[0],\n",
    "                    'rating': entry['rating'],\n",
    "                    'timestamp': 0 \n",
    "                })\n",
    "\n",
    "        new_user_data = pd.DataFrame(rows_to_add)\n",
    "        data = pd.concat([data, new_user_data])  \n",
    "        user_matrix_filled = collaborative_filtering(data)  \n",
    "\n",
    "        group = user_matrix_filled.tail(4)  # Last 4\n",
    "        explanations = generate_explanations(group, \"MPL\", 1)\n",
    "\n",
    "\n",
    "        explanation_window = tk.Tk()\n",
    "        explanation_window.title(\"Rate explanations\")\n",
    "        window_width = 1000\n",
    "        window_height = 800\n",
    "        screen_width = explanation_window.winfo_screenwidth()\n",
    "        screen_height = explanation_window.winfo_screenheight()\n",
    "\n",
    "        x_coordinate = (screen_width - window_width) // 2\n",
    "        y_coordinate = (screen_height - window_height) // 2\n",
    "    \n",
    "        explanation_window.geometry(f\"{window_width}x{window_height}+{x_coordinate}+{y_coordinate}\")\n",
    "        explanations_listbox = tk.Listbox(explanation_window, font=(\"Arial\", 12), width=80, height=20)\n",
    "        explanations_listbox.grid(row=0, column=0, padx=20, pady=20)\n",
    "\n",
    "        random_number = random.randint(0, 2)\n",
    "        explanations_listbox.insert(tk.END, explanations[random_number])\n",
    "\n",
    "        questions = [\n",
    "            \"Did you feel the recommendations were fair to all group members?\",\n",
    "            \"Did the explanation help your group reach a consensus?\",\n",
    "            \"Were you satisfied with the recommendations provided?\"\n",
    "        ]\n",
    "\n",
    "        rating_scales = []\n",
    "        current_row = 1  \n",
    "        for question in questions:\n",
    "            label = tk.Label(explanation_window, text=question, wraplength=800)\n",
    "            label.grid(row=current_row, column=0, padx=20, pady=5, sticky=tk.W)\n",
    "            current_row += 1\n",
    "\n",
    "            scale = tk.Scale(explanation_window, from_=0, to=5, orient=tk.HORIZONTAL, resolution=0.1, length=200)\n",
    "            scale.grid(row=current_row, column=0, padx=20, pady=5)\n",
    "            current_row += 1\n",
    "\n",
    "            rating_scales.append(scale)\n",
    "        # get number of users in db \n",
    " \n",
    "        def submit_and_close():\n",
    "            ratings = [scale.get() for scale in rating_scales]\n",
    "            with open(\"../Data/PreprocessedDataset/feedback_grs.csv\", 'a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(ratings)\n",
    "\n",
    "        submit_button_2 = tk.Button(explanation_window, text=\"Submit Ratings\", command=submit_and_close)\n",
    "        submit_button_2.grid(row=current_row, column=0, pady=10)\n",
    "            \n",
    "movies_list =  movies_df['title'].values.tolist()\n",
    "root = tk.Tk()\n",
    "root.title(\"Movie Rating App\")\n",
    "app = MovieRatingGUI(root, movies_list)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset_folder = \"../Data/PreprocessedDataset\"\n",
    "df = pd.read_csv(preprocessed_dataset_folder+\"/feedback_grs.csv\")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(1, 4):\n",
    "    plt.subplot(3, 1, i)\n",
    "    sns.histplot(df[f'Rating{i}'], kde=True, bins=7, color='skyblue')\n",
    "    if i == 1:\n",
    "        plt.title(f'Fairness ')\n",
    "    if i == 2:\n",
    "        plt.title(f'Consensus')\n",
    "    if i == 3:\n",
    "        plt.title(f'User satisfaction')\n",
    "    plt.xlabel(f'Rating')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating for effectiveness:  3.9357142857142855\n",
      "Average rating for trust:  2.885714285714286\n",
      "Average rating for efficiency:  1.7821428571428573\n"
     ]
    }
   ],
   "source": [
    "print(\"Average rating for effectiveness: \",df['Rating1'].mean())\n",
    "print(\"Average rating for trust: \",df['Rating2'].mean())\n",
    "print(\"Average rating for efficiency: \",df['Rating3'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
